\section{Results \& Discussion}
\label{sec:results}

\subsection{Classification Effectiveness}
\label{sec:results_effect}

\subsubsection{MNIST}
\label{sec:results_mnist}



Figure~\ref{fig:mnist} shows the accuracy of the model on the MNIST dataset. According to the result, CRIL outperformed over 21\% in average accuracy to iCaRL for all sizes of exemplar. 
Especilaly for smail size of exemplar($K=100$), CRIL shows 75\% of test accuracy for 10 classes with the budget size($K$) 100 which was 23\% higher than iCaRL (52\%).

The performance tended to decrease for the smaller number of exemplars both in iCaRL and CRIL. However, the drop rate of the accuracy is much smaller for CRIL than iCaRL. Therefore, RQ1 can be answered as the compact representation of the feature space brings better performance on the classification.

In overall cases, CRIL with difference of mean of gaussian distribution as 5 performs slightly better than CRIL with difference of mean of guassian distribution as 1. Therefore, RQ2 can be answered as setting the mean of guassian distribution further between each classes helps to increase the accuracy performance.

\subsubsection{CIFAR-100}
\label{sec:results_cifar}


Figure~\ref{fig:cifar} shows the accuracy of the model on the CIFAR-100 dataset. Both iCaRL and CRIL had poor performances, where the average accuracies were lower then 21\%. iCaRL outperformed about 10\% in average accuracy to CRIL for both $K=500\textrm{ and }1000$.

CIFAR-100 contains more diversed real world images than MNIST. Therefore it may hard for CRIL to represent the features using pure MLP architecture. We claim that the performance can be improved with CNN architecture on CRiL.

\subsection{Discussion}
\todo{t-sne}

\todo{YOUNGKI PLEASE HELP}